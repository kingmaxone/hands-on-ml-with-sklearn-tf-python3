{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用tensorflow\n",
    "\n",
    "tensorflow是一个强大的用于数值计算的开源软件，尤其适用于大型机器学习。\n",
    "基本原则很简单：首先定义要执行的计算图， 接着tensorflow载入图，用优化过的c++代码执行。\n",
    "\n",
    "最重要的是，可以将图形分割成多个块，并在多个cpu或gpu之间并行运行它们。也支持分布式计算，因此，你可以通过在数百台服务器上拆分计算，在合理的时间内训练庞大的神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# 准备工作\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# 控制随机种子，使结果一样\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建和运行数据流图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "reset_graph()\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意， 上述代码并没有执行任何计算， 即使看起来像是执行了很多计算一样。甚至呆变量也没有初始化。要执行计算，需要创建tensorflow session， 并使用它来初始化和变量和执行计算。\n",
    "Tensorflow session负责将操作放置到诸如cpu和gpu之类的设备上，并运行它们。如下执行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval() #eval:串演算指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow程序铭心分为两部分：第一部分创建计算图，第二部分执行计算。创建过程表示创建ML模型和需要的计算过程， 执行过程通常循环计算训练的每一步，逐渐改进模型的参数。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组织 数据流图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# 节点的声明周期\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  #10\n",
    "    print(z.eval())  #15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 线性回归\n",
    "\n",
    "\n",
    "tensorflow operations(ops) 可以取任意数量的输入并产生任意数量的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用标准方程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7185181e+01],\n",
       "       [ 4.3633747e-01],\n",
       "       [ 9.3952334e-03],\n",
       "       [-1.0711310e-01],\n",
       "       [ 6.4479220e-01],\n",
       "       [-4.0338000e-06],\n",
       "       [-3.7813708e-03],\n",
       "       [-4.2348403e-01],\n",
       "       [-4.3721911e-01]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与使用numpy计算对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69419202e+01],\n",
       "       [ 4.36693293e-01],\n",
       "       [ 9.43577803e-03],\n",
       "       [-1.07322041e-01],\n",
       "       [ 6.45065694e-01],\n",
       "       [-3.97638942e-06],\n",
       "       [-3.78654266e-03],\n",
       "       [-4.21314378e-01],\n",
       "       [-4.34513755e-01]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与使用sklearn对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 0.00000000e+00]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_data_plus_bias, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用梯度下降\n",
    "\n",
    "\n",
    "梯度下降首先需要进行特征缩放，可以使用tf，不过目前还是使用sklearn。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
      " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
      " -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.11111111111111005\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_housing_data_plus_bais.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bais.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bais.mean())\n",
    "print(scaled_housing_data_plus_bais.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一般方法计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  9.161543\n",
      "Epoch 100 MSE =  0.71450067\n",
      "Epoch 200 MSE =  0.5667049\n",
      "Epoch 300 MSE =  0.5555719\n",
      "Epoch 400 MSE =  0.5488112\n",
      "Epoch 500 MSE =  0.5436362\n",
      "Epoch 600 MSE =  0.5396294\n",
      "Epoch 700 MSE =  0.53650916\n",
      "Epoch 800 MSE =  0.5340678\n",
      "Epoch 900 MSE =  0.5321474\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bais, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predications\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685523 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401656],\n",
       "       [-0.34770885],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.66145283],\n",
       "       [-0.6375278 ]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用autodiff\n",
    "与上述过程一样，出了 gradients=... 这一行\n",
    "\n",
    "注意：上述过程运行的很好，但是需要从损失函数中推导出梯度。在线性回归中，求偏导数相对容易。但是如果是执行深度神经网络，这个过程会变的困难。虽然可以计算出函数的偏导数，但是得到的代码不一定有效。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bais, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.161543\n",
      "Epoch 100 MSE = 0.7145006\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.5555719\n",
      "Epoch 400 MSE = 0.5488112\n",
      "Epoch 500 MSE = 0.5436362\n",
      "Epoch 600 MSE = 0.5396294\n",
      "Epoch 700 MSE = 0.5365092\n",
      "Epoch 800 MSE = 0.5340678\n",
      "Epoch 900 MSE = 0.5321474\n",
      "Best theta:\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.6614528 ]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 如何求出如下关于a，b函数的偏导数？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754916"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autodiff\n",
    "tensorflow 的autodiff 特征可以自动并且有效的计算梯度，如下代码所示：\n",
    "gradients() 函数的将 一个op 和一个变量列表，根据每个变量执行一组列表ops操作， 计算op的梯度。 因此下面代码，gradients 将根据 $\\theta$ 和mse 操作 计算梯度向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.Variable(0.0, name=\"z0\")\n",
    "\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "\n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 下面计算函数在$a=0.2$ 和 $b=0.3$， 并且关于a, b点的偏导数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21253741\n",
      "[-1.1388494, 0.19671395]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用梯度下降优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learing_rate = 0.01\n",
    "\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.161543\n",
      "Epoch 100 MSE = 0.7145006\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.5555719\n",
      "Epoch 400 MSE = 0.5488112\n",
      "Epoch 500 MSE = 0.5436362\n",
      "Epoch 600 MSE = 0.5396294\n",
      "Epoch 700 MSE = 0.5365092\n",
      "Epoch 800 MSE = 0.5340678\n",
      "Epoch 900 MSE = 0.5321474\n",
      "Best theta:\n",
      "[[ 2.0685525 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401658]\n",
      " [-0.34770882]\n",
      " [ 0.36178368]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.6614528 ]\n",
      " [-0.6375277 ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 动量优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.068558  ]\n",
      " [ 0.8296286 ]\n",
      " [ 0.11875337]\n",
      " [-0.26554456]\n",
      " [ 0.3057109 ]\n",
      " [-0.00450251]\n",
      " [-0.03932662]\n",
      " [-0.89986444]\n",
      " [-0.87052065]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将数据输入到训练算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 占位节点 (Placeholder nodes)\n",
    "该节点不执行任何运算，只是输出你告诉他们在运行时输出的数据。\n",
    "在训练过程中，它们通常被用来将训练数据传递给TensorFlow。如果在运行时没有为占位符指定值，则会得到一个异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A:[[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A:[[4, 5, 6], [7, 8, 9]]})\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小批量梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42),name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epochs, batch_index, batch_size):\n",
    "    np.random.seed(epochs * n_batches + batch_index)\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存和加载模型\n",
    "模型训练完之后，需要保存参数，以便后续使用， 或者和其他模型比较。\n",
    "或者在运行过程中有规律的保存模型，防止程序崩溃后，又重新开始。\n",
    "\n",
    "使用tensorflow的saver可以方便的保存和加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 9.161543\n",
      "Epoch 100 MSE = 0.7145006\n",
      "Epoch 200 MSE = 0.566705\n",
      "Epoch 300 MSE = 0.5555719\n",
      "Epoch 400 MSE = 0.5488112\n",
      "Epoch 500 MSE = 0.5436362\n",
      "Epoch 600 MSE = 0.5396294\n",
      "Epoch 700 MSE = 0.5365092\n",
      "Epoch 800 MSE = 0.5340678\n",
      "Epoch 900 MSE = 0.5321474\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000                                                                       # not shown in the book\n",
    "learning_rate = 0.01                                                                  # not shown\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # not shown\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # not shown\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      # not shown\n",
    "error = y_pred - y                                                                    # not shown\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # not shown\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # not shown\n",
    "training_op = optimizer.minimize(mse)                                                 # not shown\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())                                # not shown\n",
    "            save_path = saver.save(sess, \"../tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"../tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685525 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401658],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614528 ],\n",
       "       [-0.6375277 ]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"../tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() # not shown in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想换一个名字保存， 可以使用如下方法：\n",
    "saver = tf.train.Saver({\"weights\": theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认的，saver还将计算图本身保存在扩展名为.meta的第二个文件中。 可以使用函数`tf.train.import_mate_graph()`重载计算图。\n",
    "这个函数将图形加载到默认图中，并返回一个可用于恢复图状态的Saver。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "# 开始为空\n",
    "saver = tf.train.import_meta_graph(\"../tmp/my_model_final.ckpt.meta\")\n",
    "theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"../tmp/my_model_final.ckpt\")\n",
    "    best_theta_restore = theta.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这意味着 可以导入之间训练过得模型， 而不必用相应的python代码来构建计算图。\n",
    "当您不断调整并保存您的模型时，这非常有用:您可以加载以前保存的模型，而不必搜索构建它的代码的版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化计算图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '\"'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用tensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"../tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()                                                     # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255151],\n",
       "       [-0.31211874],\n",
       "       [ 0.38510373],\n",
       "       [ 0.00434168],\n",
       "       [-0.01232954],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上述保存的文件， 执行如下命令可以进行可视化：\n",
    "```\n",
    "    $ tensorboard --logdir tf_logs/\n",
    "    Starting TensorBoard  on port 6006\n",
    "    (You can navigate to http://0.0.0.0:6006)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量作用域\n",
    "当处理很复杂的模型(神经网络)时，这个图形很容易被成千上万个节点所包围。为了避免这种情况，您可以为相关的节点创建作用域。 如下代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"../tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.0703337 ]\n",
      " [ 0.8637145 ]\n",
      " [ 0.12255151]\n",
      " [-0.31211874]\n",
      " [ 0.38510373]\n",
      " [ 0.00434168]\n",
      " [-0.01232954]\n",
      " [-0.83376896]\n",
      " [-0.8030471 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush()\n",
    "file_writer.close()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a_1\n",
      "param/a\n",
      "param_1/a\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "a1 = tf.Variable(0,name=\"a\")\n",
    "a2 = tf.Variable(0,name=\"a\")\n",
    "\n",
    "with tf.name_scope(\"param\"):\n",
    "    a3 = tf.Variable(0, name=\"a\")\n",
    "\n",
    "with tf.name_scope(\"param\"):       # name == \"param_1\"\n",
    "    a4 = tf.Variable(0, name=\"a\")  # name == \"param_1/a\"\n",
    "\n",
    "for node in (a1, a2, a3, a4):\n",
    "    print(node.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面代码结构比较差：\n",
    "n_features = 3\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "b1 = tf.Variable(0.0, name=\"bias1\")\n",
    "b2 = tf.Variable(0.0, name=\"bias2\")\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
    "relu2 = tf.maximum(z1, 0., name=\"relu2\")  # Oops, cut&paste error! Did you spot it?\n",
    "\n",
    "output = tf.add(relu1, relu2, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行一些改进\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu1\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更好的是使用scopes：\n",
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                          # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")    # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                             # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                      # not shown\n",
    "        return tf.maximum(z, 0., name=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 共享变量\n",
    "当不同代码需要使用同一个变量时，可以当做参数，或者新建字典，新建类来访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X, threshold):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        if not hasattr(relu, \"threshold\"):\n",
    "            relu.threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # not shown in the book\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, relu.threshold, name=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf提供了另一种方法， 使用 get_variable() 函数，创建共享变量(不存在创建，存在重用)。其行为由variable_scope() 函数来控制。\n",
    "比如下面代码 新建一个变量 \"resu/threshold\"。 \n",
    "\n",
    "但是这种情况下，如果变量之前已经存在， 会报异常， 因此用于防止变量错误重用。  \n",
    "\n",
    "第二段代码则添加reuse属性，不用指定shape和初始化，可以重用变量。 将会寻找已经存在的变量，不存在则报异常。  \n",
    "\n",
    "第三段代码则将resue放在代码块里面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "with tf.variable_scope(\"relu\", reuse=True):\n",
    "    threshold = tf.get_variable(\"threshold\")\n",
    "    \n",
    "with tf.variable_scope(\"relu\") as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # not shown\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu6\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\"):\n",
    "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"\", default_name=\"\") as scope:\n",
    "    first_relu = relu(X)     # create the shared variable\n",
    "    scope.reuse_variables()  # then reuse it\n",
    "    relus = [first_relu] + [relu(X) for i in range(4)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu8\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
    "    b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu9\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 补充资料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "    x0 = tf.get_variable(\"x\", shape=(), initializer=tf.constant_initializer(0.))\n",
    "    x1 = tf.Variable(0., name=\"x\")\n",
    "    x2 = tf.Variable(0., name=\"x\")\n",
    "\n",
    "with tf.variable_scope(\"my_scope\", reuse=True):\n",
    "    x3 = tf.get_variable(\"x\")\n",
    "    x4 = tf.Variable(0., name=\"x\")\n",
    "    \n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):\n",
    "    x5 = tf.get_variable(\"my_scope/x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: my_scope/x\n",
      "x1: my_scope/x_1\n",
      "x2: my_scope/x_2\n",
      "x3: my_scope/x\n",
      "x4: my_scope_1/x\n",
      "x5: my_scope/x\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"x0:\", x0.op.name)\n",
    "print(\"x1:\", x1.op.name)\n",
    "print(\"x2:\", x2.op.name)\n",
    "print(\"x3:\", x3.op.name)\n",
    "print(\"x4:\", x4.op.name)\n",
    "print(\"x5:\", x5.op.name)\n",
    "print(x0 is x3 and x3 is x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Do' b'you' b'want' b'some' b'caf\\xc3\\xa9?']\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "text = np.array(\"Do you want some café?\".split())\n",
    "text_tensor = tf.constant(text)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(text_tensor.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课后习题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.创建计算图相比直接计算的优点是什么?主要的缺点是什么？\n",
    "优点：\n",
    "tensorflow可以使用reverse-mode autodiff自动计算梯度。\n",
    "TensorFlow可以处理在不同线程中并行运行的操作\n",
    "在不同设备运行相同的模型\n",
    "可以在TensorBoard中查看模型\n",
    "\n",
    "缺点：\n",
    "学习曲线更加陡峭，调试更加困难。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. a_val = a.eval(session=sess) 与 a_val = sess.run(a) 的结果相等吗？ \n",
    "相等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. a_val, b_val = a.eval(session=sess), b.eval(ses sion=sess)和 a_val, b_val = sess.run([a, b]) 的计算结果相等吗？\n",
    "不相等。   \n",
    "前者两次执行计算图， 后者只执行一次。  \n",
    "如果任何op有副作用， 其结果也会不同。如果没有副作用，两个返回结果相同，但是后者运行速度好于前者。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 在同一个session 中可以执行两个计算图吗？\n",
    "不行，不能在同一个session中执行两个计算图。必须合并到一个计算图中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 如果创建包含变脸w的计算图g，启动两个线程并每个线程打开一个session，都同时用到g， 每个session拥有各自独立的w还是共享w？\n",
    "在本地tensorfolw中，session管理变量。如题目所示，每个session有拥有w的副本。然而在分布式tensorflow中，变由cluster保存并管理，如果两个session都使用用一个容器， 连接到同一个cluster，则共享变量w。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 变量什么时候初始化？什么时候销毁？\n",
    "当调用initializer时初始化，当sessions结束时销毁。在分布式tensorflow中，变量保存在cluster的容器中， session关闭并不会销毁变量， 而是清理container时销毁。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. placeholder和variable之前的区别是什么？\n",
    "有极大的不同:\n",
    "variable是持有值的操作。如果运行variable， 返回值。在运行之前， 需要初始化。可以修改其值（比如使用 assignment 操作）。它是有状态的：变量在图的连续运行中保持相同的值。\n",
    "它是一种类型，用于保存模型参数，但也用于其他目的(例如，计算全局训练步骤)。\n",
    "\n",
    "而Placeholders: 只是持有type和shape的tensor的信息，没有确切的值。实际上， 如果计算一个依赖placeholder的操作，必须提供相应的值(feed_dict),否则会得到一个异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. 当去计算一个op， 其placeholder还没有feed数据的时候会发生什么？如果该op不依赖placeholder又会发生什么？\n",
    "会得到一个异常。  如果不依赖placeholder， 没有异常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. 当运行计算图时， 能提供任何操作的输出值，还是只是占位符的值吗？\n",
    "当您运行一个图表时，您可以提供任何操作的输出值，而不仅仅是占位符的值。然而，在实践中，这是相当罕见的(例如，当您在缓存冻结层的输出时，它可能是有用的)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. 如何将变量设置为您想要的任何值(在执行阶段)?\n",
    "当创建计算图时可以指定变量的初始值，之后在执行语句，运行初始化时变量将会被初始化。如果在后面的运行过程中先改变变量的值，最简单的操作是使用赋值语句（在创建图语句中） tf.assign()语句， 传入变量和placeholder。在执行阶段，可以运行赋值操作，提供新的变量值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. 当计算包含10个变量的损失函数的梯度时，reverse-mode autodiff 需要遍历多少次计算图？如果是forward-mode autodiff呢？区别是什么？\n",
    "reverse-mode autodiff 需要遍历两次计算图，以便计算损失函数的梯度。另一方面， forward-mode autodiff 需要根据变量数，每个变量遍历一次。  \n",
    "明显的区别在于，后者会创建一个不同的计算图去计算梯度，而不是遍历原计算图。\n",
    "一个高度优化的系统可能只需要一次运行新的梯度图来计算所有变量的梯度，但是新的图形可能会非常复杂和低效，与原始图相比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. 用小批量梯度下降实现逻辑回归。在moons 数据集上训练并计算。 \n",
    "1. 定义计算图， logistics_regerssion(), 实现函数重用。\n",
    "2. 在训练过程中，定期使用Saver保存检查点，并在训练结束时保存最终的模型。\n",
    "3. 如果程序中断，  重载最后保存的模型。\n",
    "4. 使用漂亮的范围来定义图表，这样图表看起来很好。\n",
    "5. 添加summaries ， 便于可视化。\n",
    "6. 试着调整一些超参数，比如学习速率或者小批量大小，看看学习曲线的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11426c7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)\n",
    "\n",
    "# 可视化\n",
    "plt.plot(X_moons[y_moons==1, 0], X_moons[y_moons==1, 1], \"go\", label=\"positive\")\n",
    "plt.plot(X_moons[y_moons==0, 0], X_moons[y_moons==0, 1], \"r^\", label=\"positive\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不能忘记忘记对每个实例添加偏置项（$x_0 = 1$）。需要在矩阵的左边遍历一列。\n",
    "X_moons_with_bias = np.c_[np.ones([m, 1]), X_moons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.05146968,  0.44419863],\n",
       "       [ 1.        ,  1.03201691, -0.41974116],\n",
       "       [ 1.        ,  0.86789186, -0.25482711],\n",
       "       [ 1.        ,  0.288851  , -0.44866862],\n",
       "       [ 1.        , -0.83343911,  0.53505665]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#简单检查\n",
    "X_moons_with_bias[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#现在变换y_train为列向量，（每行是2D 数组）。\n",
    "y_moons_column_vector = y_moons.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分数据为训练集和测试集\n",
    "test_radio = 0.2\n",
    "test_size = int(m * 0.2)\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_test = X_moons_with_bias[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面创建一个生成训练集的函数。随机选取每个批量的训练实例。意味着单独的patch可能会多次包括相同的实例， 并且可能不会全覆盖到所有的实例。然而，实际上问题不大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.81702614, -0.41205437],\n",
       "       [ 1.        , -0.14780171,  0.16037205],\n",
       "       [ 1.        ,  1.07172763,  0.13482039],\n",
       "       [ 1.        , -0.83986573,  0.31168093],\n",
       "       [ 1.        , -0.72480745,  1.05480753]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看一下随机的结果\n",
    "X_batch, y_batch = random_batch(X_train, y_train, 5)\n",
    "X_batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 准备工作已经做好，准备创建模型，提供数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入数据有两个特征，是2维的。\n",
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建逻辑回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name=\"logits\")\n",
    "y_proba = 1 / (1 + tf.exp(-logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实际上，tf提供了sigmod函数：\n",
    "y_proba = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(\\mathbf{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7 # 防止计算时溢出\n",
    "loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (1 - y) * (tf.log(1 - y_proba + epsilon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时也可以使用tf的内置函数：\n",
    "loss = tf.losses.log_loss(y, y_proba)  # uses epsilon = 1e-7 by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "余下的部分：创建优化器并且优化损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行初始化语句\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来开始训练模型并进行预测。 \n",
    "代码与之前线性回归的类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (200, 3) for Tensor 'y:0', which has shape '(?, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-6396b13541c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\tLoss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \"\"\"\n\u001b[0;32m--> 710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5178\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5180\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1111\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1112\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (200, 3) for Tensor 'y:0', which has shape '(?, 1)'"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
